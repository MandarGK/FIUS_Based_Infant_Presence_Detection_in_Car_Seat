{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce11124-3ce8-4653-8df7-7fca13654144",
   "metadata": {},
   "outputs": [],
   "source": [
    "'Baby presence detection with obstructions like Sunscreen and Blanket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd3de8d-52f1-413a-95bb-abb3ba131186",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "190ff70c-e7f4-4b53-9370-3aedd00ff428",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e429e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import every packages for EDA\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bbf181",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f286b0",
   "metadata": {},
   "source": [
    "# Add measurements for withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4ff986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os \n",
    "# Replace 'your_array_file.npy' with the actual file path of your saved NumPy array\n",
    "#file_path = 'Carrierseat_withoutbaby_npy_array_Lowpassfiltered_label_0.npy'\n",
    "\n",
    "# Path to the file (same as used when saving)\n",
    "file_path = os.path.join(\"..\", \"..\", \"Data\", \"Processed\",\n",
    "    \"CarrierSeat_withoutBaby_Lowpassfilered_Label_0.npy\")\n",
    "\n",
    "\n",
    "# Load the NumPy array from the file\n",
    "loaded_array = np.load(file_path, mmap_mode='r')\n",
    "\n",
    "# Now 'loaded_array' contains the NumPy array data that was saved in the file\n",
    "dataframe_withoutbaby = pd.DataFrame(loaded_array,columns=['Frequency','FFT Magnitude','Phase','Infant_Presence'])\n",
    "dataframe_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b22ccbb-83dc-4442-b6b7-dbe8241f09fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_withoutbaby = len(dataframe_withoutbaby)\n",
    "num_rows_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0c324-c18b-4dc9-a2ad-5cf09f7716f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_magnitudes_withoutbaby = dataframe_withoutbaby[\"FFT Magnitude\"].values  # Convert to NumPy array\n",
    "fft_magnitudes_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9039c0c-500a-4055-b9e0-c2218801394f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_frequencies_withoutbaby = dataframe_withoutbaby[\"Frequency\"].values  # Convert to NumPy array\n",
    "fft_frequencies_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05209c2-b05a-42bc-bcc7-7103422ce8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_phase_withoutbaby = dataframe_withoutbaby[\"Phase\"].values  # Convert to NumPy array\n",
    "fft_phase_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60698901-8842-4068-a367-cbc2a3f0f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import entropy\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "def extract_features(fft_freqs, fft_mags, fft_phase):\n",
    "    # Normalize magnitudes to prevent division errors\n",
    "    norm_mags = fft_mags / np.sum(fft_mags) if np.sum(fft_mags) > 0 else fft_mags\n",
    "    \n",
    "    # Spectral Centroid (Weighted Mean of Frequencies)\n",
    "    spectral_centroid = np.sum(fft_freqs * norm_mags) / np.sum(norm_mags)\n",
    "\n",
    "    # Spectral Bandwidth (Spread around centroid)\n",
    "    spectral_bandwidth = np.sqrt(np.sum(norm_mags * (fft_freqs - spectral_centroid) ** 2))\n",
    "\n",
    "    # Spectral Flatness (Geometric Mean / Arithmetic Mean)\n",
    "    spectral_flatness = np.exp(np.mean(np.log(fft_mags + 1e-10))) / np.mean(fft_mags + 1e-10)\n",
    "\n",
    "    # Find peaks in the magnitude spectrum\n",
    "    peaks, _ = find_peaks(fft_mags, height=0.1 * np.max(fft_mags))  # Adaptive threshold\n",
    "\n",
    "    # Harmonic Ratio (Ratio of 2nd peak to 1st peak)\n",
    "    if len(peaks) >= 2:\n",
    "        harmonic_ratio = fft_mags[peaks[1]] / fft_mags[peaks[0]]\n",
    "    else:\n",
    "        harmonic_ratio = 0  # No second peak detected\n",
    "\n",
    "    # Phase Features\n",
    "    phase_variance = np.var(fft_phase)  # Variance of phase angles\n",
    "    phase_mean = np.mean(fft_phase)  # Mean of phase angles\n",
    "    phase_diff = np.mean(np.diff(fft_phase))  # Average phase difference between frequencies\n",
    "\n",
    "    return {\n",
    "        \"mean_fft\": np.mean(fft_mags),\n",
    "        \"std_fft\": np.std(fft_mags),\n",
    "        \"max_fft\": np.max(fft_mags),\n",
    "        \"min_fft\": np.min(fft_mags),\n",
    "        \"median_fft\": np.median(fft_mags),\n",
    "        \"sum_fft\": np.sum(fft_mags),\n",
    "        \"spectral_entropy\": entropy(norm_mags),  # Energy spread\n",
    "        \"spectral_centroid\": spectral_centroid,\n",
    "        \"spectral_bandwidth\": spectral_bandwidth,\n",
    "        \"spectral_flatness\": spectral_flatness,\n",
    "        \"phase_variance\": phase_variance,\n",
    "        \"phase_mean\": phase_mean,\n",
    "        \"phase_diff\": phase_diff,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f99ff2-035b-424f-8f54-7c33315e733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply perturbation based on reference values\n",
    "def add_perturbation(reference_features, num_rows, perturb_range=0.03):\n",
    "    perturbed_data = []\n",
    "    \n",
    "    for _ in range(num_rows):\n",
    "        perturbed_features = {\n",
    "            key: value * (1 + np.random.uniform(-perturb_range, perturb_range)) \n",
    "            for key, value in reference_features.items()\n",
    "        }\n",
    "        perturbed_data.append(perturbed_features)\n",
    "    \n",
    "    return pd.DataFrame(perturbed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7020c46-757b-4079-b1bf-cd1196cf6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Extract features for fft_withoutbaby\n",
    "reference_features_withoutbaby = extract_features(fft_frequencies_withoutbaby, fft_magnitudes_withoutbaby, fft_phase_withoutbaby)\n",
    "reference_features_withoutbaby\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442dc0c4-31b8-4ef7-81ea-fded2092578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a DataFrame with perturbed values for all rows in fft_withoutbaby\n",
    "num_rows_withoutbaby = len(dataframe_withoutbaby)\n",
    "perturbed_withoutbaby_df = add_perturbation(reference_features_withoutbaby, num_rows_withoutbaby, perturb_range=0.03)\n",
    "perturbed_withoutbaby_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7596cbe7-7bba-4f4a-8d22-b193831da61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df31926",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a1d5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perturbed_withoutbaby_df),len(dataframe_withoutbaby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656e2694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure both DataFrames have the same number of rows\n",
    "if len(dataframe_withoutbaby) != len(perturbed_withoutbaby_df):\n",
    "    print(\"The DataFrames have different lengths. Adjust them to have the same number of rows before concatenating.\")\n",
    "else:\n",
    "    # Concatenate the DataFrames side by side\n",
    "    dataframe_withoutbaby_withfeatures = pd.concat([dataframe_withoutbaby, perturbed_withoutbaby_df], axis=1)\n",
    "\n",
    "# Display the first few rows of the updated dataframe_withoutbaby to verify\n",
    "dataframe_withoutbaby_withfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8565aa0c",
   "metadata": {},
   "source": [
    "# Withbaby covered with blanket and sunscreen measurements "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a40f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Replace 'your_array_file.npy' with the actual file path of your saved NumPy array\n",
    "file_path = os.path.join(\"..\", \"..\", \"Data\", \"Processed\",\n",
    "    \"BabyCovered_with_Blanket_or_Sunscreen_npy_array_Lowpassfiltered_label.npy\")\n",
    "\n",
    "# Load the NumPy array from the file\n",
    "loaded_array = np.load(file_path, mmap_mode='r')\n",
    "\n",
    "# Now 'loaded_array' contains the NumPy array data that was saved in the file\n",
    "dataframe_withbaby = pd.DataFrame(loaded_array,columns=['Frequency','FFT Magnitude','Phase','Infant_Presence'])\n",
    "dataframe_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e954e7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows_withbaby = len(dataframe_withbaby)\n",
    "num_rows_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3883348e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_magnitudes_withbaby = dataframe_withbaby[\"FFT Magnitude\"].values  # Convert to NumPy array\n",
    "fft_magnitudes_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2848c2-6998-4dda-acfb-ffdf1f9d3de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_frequencies_withbaby = dataframe_withbaby[\"Frequency\"].values  # Convert to NumPy array\n",
    "fft_frequencies_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003bca7d-081f-4ae5-b8c0-ec8e5c7dc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fft_phase_withbaby = dataframe_withbaby[\"Phase\"].values  # Convert to NumPy array\n",
    "fft_phase_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dacef91-d3f8-425e-88ac-1794f83e3cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for fft_withbaby\n",
    "reference_features_withbaby = extract_features(fft_frequencies_withbaby, fft_magnitudes_withbaby, fft_phase_withbaby)\n",
    "reference_features_withbaby\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66b55ac-14ae-491b-85d4-f86c3c9b5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a DataFrame with perturbed values for all rows in fft_withoutbaby\n",
    "num_rows_withbaby = len(dataframe_withbaby)\n",
    "perturbed_withbaby_df = add_perturbation(reference_features_withbaby, num_rows_withbaby, perturb_range=0.03)\n",
    "perturbed_withbaby_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda280b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a26e34-0915-47fc-9d5c-c340af7012f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(perturbed_withbaby_df),len(dataframe_withbaby)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039586b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ensure both DataFrames have the same number of rows\n",
    "if len(dataframe_withbaby) != len(perturbed_withbaby_df):\n",
    "    print(\"The DataFrames have different lengths. Adjust them to have the same number of rows before concatenating.\")\n",
    "else:\n",
    "    # Concatenate the DataFrames side by side\n",
    "    dataframe_withbaby_withfeatures = pd.concat([dataframe_withbaby, perturbed_withbaby_df], axis=1)\n",
    "\n",
    "# Display the first few rows of the updated dataframe_withoutbaby to verify\n",
    "dataframe_withbaby_withfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87e66ac-90e6-4959-927e-2fd3bcd5f0b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcf19e9-77b1-4f6f-9a1d-10caec213e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_withoutbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0140a23-9a42-4480-9497-8899f3119b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_withbaby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8976101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical concatenation\n",
    "dataset_2_rawdata = pd.concat([dataframe_withoutbaby,dataframe_withbaby])\n",
    "dataset_2_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322b5559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index if unique indices are needed\n",
    "dataset_2_rawdata = dataset_2_rawdata.reset_index(drop=True)\n",
    "dataset_2_rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74946fc5-10d1-43a3-a7fd-30ac282cafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_withbaby_withfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab1ffe-8993-4853-8d16-b3f2d5fbd202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_withoutbaby_withfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9db9019-61a3-4322-ab91-ee0a81609200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vertical concatenation\n",
    "dataset_2_withfeatures = pd.concat([dataframe_withoutbaby_withfeatures,dataframe_withbaby_withfeatures])\n",
    "dataset_2_withfeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e9dd54-8a3e-4244-93d0-e4139a95ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting the index if unique indices are needed\n",
    "dataset_2_withfeatures = dataset_2_withfeatures.reset_index(drop=True)\n",
    "dataset_2_withfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d6693d",
   "metadata": {},
   "source": [
    "# Training with rawdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b423796-151e-4a93-9084-7cc3304bad29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef58f6-de4f-4a76-98e3-c65e2d8fe4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (df_combined)\n",
    "X = dataset_2_rawdata.drop(columns=['Infant_Presence'])  # Features\n",
    "y = dataset_2_rawdata['Infant_Presence']  # Labels\n",
    "\n",
    "# Split into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (XGBoost handles unscaled data well, but scaling can help)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data into DMatrix format (optimized for XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',        # Loss function\n",
    "    'max_depth': 6,                   # Depth of trees\n",
    "    'learning_rate': 0.1,              # Step size shrinkage\n",
    "    'n_estimators': 1000,               # Number of trees\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report for rawdata:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f448e17-0230-4156-ad97-9b95361882cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax)  # Use fmt='d' for integer annotation\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title('Confusion Matrix Baby presence detection when covered in Blanket or sunscreen- XG Boost Model with rawdata')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f301dff7-a6e6-484c-a698-74cf4b659ef9",
   "metadata": {},
   "source": [
    "# Training with extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997ab8b-536d-45ca-869e-1913353d0c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XG Boost Model with extracted features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a621b6b-1f26-4a0e-9ec1-7883fc5780b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1b68c-d532-4c15-aed5-cba6260a5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset (df_combined)\n",
    "X = dataset_2_withfeatures.drop(columns=['Infant_Presence'])  # Features\n",
    "y = dataset_2_withfeatures['Infant_Presence']  # Labels\n",
    "\n",
    "# Split into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (XGBoost handles unscaled data well, but scaling can help)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data into DMatrix format (optimized for XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',        # Loss function\n",
    "    'max_depth': 6,                   # Depth of trees\n",
    "    'learning_rate': 0.1,              # Step size shrinkage\n",
    "    'n_estimators': 1000,               # Number of trees\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report for extracted features data:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7761b377-a5df-4af7-802a-4e7dc358ea83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax)  # Use fmt='d' for integer annotation\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title('Confusion Matrix Baby presence detection when covered in Blanket or sunscreen - XG Boost Model with extracted features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde8b2bd-6ac0-4dad-aa39-c17e54728c69",
   "metadata": {},
   "source": [
    "# Feature selection for overcoming OVERFITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd10d843-f162-4503-9ec5-69f7bbb342ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting correlation matrix for extracted features\n",
    "corr_matrix = dataset_2_withfeatures.corr()\n",
    "fig= plt.subplots(figsize=(15, 10))\n",
    "ax= sns.heatmap(corr_matrix,\n",
    "               annot=True,\n",
    "               linewidths=0.5,\n",
    "               fmt='.2f',\n",
    "               cmap='YlGnBu')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed095df-99ad-4059-ba82-02a0e68b719c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a threshold for correlation (e.g., 0.8)\n",
    "threshold = 0.8\n",
    "\n",
    "# Find pairs of highly correlated features\n",
    "highly_correlated = np.where(np.abs(corr_matrix) > threshold)\n",
    "\n",
    "# Create a set to store the columns to drop\n",
    "to_drop = set()\n",
    "\n",
    "# Loop through the indices of the highly correlated pairs\n",
    "for i, j in zip(*highly_correlated):\n",
    "    if i != j:  # Avoid diagonal (self-correlation)\n",
    "        feature_i = corr_matrix.columns[i]\n",
    "        feature_j = corr_matrix.columns[j]\n",
    "        # Ensure we do NOT drop 'Object_Presence'\n",
    "        if feature_j != \"Infant_Presence\":\n",
    "            to_drop.add(feature_j)  # Drop one of the correlated features\n",
    "\n",
    "# Drop the highly correlated features from the dataframe\n",
    "dataset_2_reduced = dataset_2_withfeatures.drop(columns=to_drop)\n",
    "\n",
    "# Display the dropped features and new dataframe shape\n",
    "print(\"Dropped features: \", to_drop)\n",
    "print(\"New dataframe shape: \", dataset_2_reduced.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443c37d2-5c41-4d6c-8bf7-bedec4918812",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b52b935-e775-4821-b6ae-a3cfabd3629f",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix = dataset_2_reduced.corr()\n",
    "fig= plt.subplots(figsize=(15, 10))\n",
    "ax= sns.heatmap(corr_matrix,\n",
    "               annot=True,\n",
    "               linewidths=0.5,\n",
    "               fmt='.2f',\n",
    "               cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1959a8f-6bf7-441b-9401-ce1a4450290a",
   "metadata": {},
   "source": [
    "# XG BOOST with selected features using Correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277c4169-3b3c-4609-9daa-a6cb94053e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load your dataset (df_combined)\n",
    "X = dataset_2_reduced.drop(columns=['Infant_Presence'])  # Features\n",
    "y = dataset_2_reduced['Infant_Presence']  # Labels\n",
    "\n",
    "# Split into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features (XGBoost handles unscaled data well, but scaling can help)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert data into DMatrix format (optimized for XGBoost)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# Set up XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',  # For binary classification\n",
    "    'eval_metric': 'logloss',        # Loss function\n",
    "    'max_depth': 6,                   # Depth of trees\n",
    "    'learning_rate': 0.1,              # Step size shrinkage\n",
    "    'n_estimators': 1000,               # Number of trees\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "# Train XGBoost model\n",
    "clf = xgb.XGBClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report for selected features data:\\n\", classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa499d2-de1f-4ed4-a1e4-aefd6ed908ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax)  # Use fmt='d' for integer annotation\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title('Confusion Matrix Baby presence detection when covered in Blanket or sunscreen -  XG Boost Model - selected features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662576fa-90f8-413a-a11b-f41d9554e375",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Compute ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Compute AUC score\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "auc_score\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing (AUC = 0.5)\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985f9131-71d8-4491-9028-bea35726ae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=importance_df[\"Importance\"], y=importance_df[\"Feature\"], palette=\"viridis\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance Chart - Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e6f4eb-dcc5-4d3f-badc-2dca7540cc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Save the trained XGBoost model\n",
    "# clf.save_model('xgboost_model_Baby_Covered_in_Blanket_Sunscreen.json')\n",
    "\n",
    "# Save the scaler\n",
    "# joblib.dump(scaler, 'xgboost_scaler_Baby_Covered_in_Blanket_Sunscreen.pkl')\n",
    "\n",
    "# Define save directories (2 levels up)\n",
    "misc_dir = os.path.join(\"..\", \"..\", \"Misc\")\n",
    "model_dir = os.path.join(\"..\", \"..\", \"Models\", \"Baby Detection and Seat Classification XGBoost\")\n",
    "\n",
    "\n",
    "# Define file paths\n",
    "model_path = os.path.join(misc_dir, \"xgboost_model_Baby_Covered_in_Blanket_Sunscreen.json\")\n",
    "scaler_path = os.path.join(model_dir, \"xgboost_scaler_Baby_Covered_in_Blanket_Sunscreen.pkl\")\n",
    "\n",
    "# --- Check and replace model ---\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(f\"Old model removed: {model_path}\")\n",
    "\n",
    "clf.save_model(model_path)\n",
    "print(f\"New model saved at: {os.path.abspath(model_path)}\")\n",
    "\n",
    "# --- Check and replace scaler ---\n",
    "if os.path.exists(scaler_path):\n",
    "    os.remove(scaler_path)\n",
    "    print(f\"Old scaler removed: {scaler_path}\")\n",
    "\n",
    "joblib.dump(scaler, scaler_path)\n",
    "print(f\"New scaler saved at: {os.path.abspath(scaler_path)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2e398f-beed-4635-aa48-464baa460ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Load the trained XGBoost model\n",
    "#clf = xgb.XGBClassifier()\n",
    "#clf.load_model('xgboost_model_Baby_Covered_in_Blanket_Sunscreen.json')\n",
    "\n",
    "# Load the scaler\n",
    "#scaler = joblib.load('xgboost_scaler_Baby_Covered_in_Blanket_Sunscreen.pkl')\n",
    "\n",
    "# Example: Transform new data and make predictions\n",
    "#X_new_scaled = scaler.transform(X_new)\n",
    "#y_pred = clf.predict(X_new_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e44ad5e-446d-4333-ae7e-7c6cca3597dd",
   "metadata": {},
   "source": [
    "# Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a082c2-efbe-4065-81b4-3008190d885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model with raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b549cc4-4845-4877-b92f-b24b439e25d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X = dataset_2_rawdata.drop('Infant_Presence',axis=1)\n",
    "Y = dataset_2_rawdata['Infant_Presence']\n",
    "\n",
    "# Split into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=10, min_samples_split = 2, min_samples_leaf = 2, max_features = \"sqrt\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"RanFor Accuracy for rawdata:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report for rawdata:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b14928-aced-401f-bf71-046e29aec39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm =confusion_matrix(y_test,y_pred)\n",
    "sns.set(font_scale=1)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax)  # Use fmt='d' for integer annotation\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title('Confusion Matrix Baby presence detection when covered in Blanket or sunscreen - RanFor - rawdata ')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c189d026-b1e7-4a04-8c02-9cf32f8f9d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cf02d1-ca41-4322-ad5c-cd8f12406005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Model with extracted features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef33b47-c0d2-4a02-bfdd-e68375a28ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X = dataset_2_withfeatures.drop('Infant_Presence',axis=1)\n",
    "Y = dataset_2_withfeatures['Infant_Presence']\n",
    "\n",
    "# Split into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=10, min_samples_split = 2, min_samples_leaf = 2, max_features = \"sqrt\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"RanFor Accuracy for extracted features data:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report for extracted features data:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead67b49-cd97-40c4-93d6-58ea94ba4c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm =confusion_matrix(y_test,y_pred)\n",
    "sns.set(font_scale=1)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax)  # Use fmt='d' for integer annotation\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title('Confusion Matrix Baby presence detection when covered in Blanket or sunscreen - RanFor - extracted features data ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f8d25-762f-49fd-a64b-e43198f4ac83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0889a6-e56f-48b5-8ae6-bf2975fc410f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest Model with selected features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d394c-f45a-4b58-a0a0-0132b1cf57eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA  # Import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "X = dataset_2_reduced.drop('Infant_Presence',axis=1)\n",
    "Y = dataset_2_reduced['Infant_Presence']\n",
    "\n",
    "# Split into training & testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "clf = RandomForestClassifier(n_estimators=1000, max_depth=10, min_samples_split = 2, min_samples_leaf = 2, max_features = \"sqrt\", random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"RanFor Accuracy for selected features data:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report for selected features data:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59814442-dbc5-4915-a92c-e5cdf2f10162",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm =confusion_matrix(y_test,y_pred)\n",
    "sns.set(font_scale=1)\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', ax=ax)  # Use fmt='d' for integer annotation\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.ylabel(\"True label\")\n",
    "plt.title('Confusion Matrix Baby presence detection when covered in Blanket or sunscreen - RanFor - selected features ')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78029df-6722-4cb7-8d87-8110a16a33d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance Plot\n",
    "importances = clf.feature_importances_\n",
    "feature_names = X.columns\n",
    "importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})\n",
    "importance_df = importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(x=importance_df[\"Importance\"], y=importance_df[\"Feature\"], palette=\"viridis\")\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.title(\"Feature Importance Chart - Random Forest\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909321c8-5691-4bc9-9d2e-f609c9aa370b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_prob = clf.predict_proba(X_test)[:, 1]  # Probability of positive class\n",
    "\n",
    "# Compute ROC curve values\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_prob)\n",
    "\n",
    "# Compute AUC score\n",
    "auc_score = roc_auc_score(y_test, y_prob)\n",
    "auc_score\n",
    "# Plot ROC Curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_score:.2f})\", color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guessing (AUC = 0.5)\")\n",
    "plt.xlabel(\"False Positive Rate (FPR)\")\n",
    "plt.ylabel(\"True Positive Rate (TPR)\")\n",
    "plt.title(\"ROC Curve\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893970ae-48d2-458b-bc3a-326389ec7ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "# Save the model\n",
    "# joblib.dump(clf, 'random_forest_model_Baby_Covered_in_Blanket_Sunscreen.pkl')\n",
    "\n",
    "# Define save directory (2 levels up -> Model/Baby Covered in Blanket Sunscreen)\n",
    "model_dir = os.path.join(\"..\", \"..\", \"Models\", \"Baby Detection and Seat Classification Random Forest\")\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "# Define model path\n",
    "model_path = os.path.join(model_dir, \"random_forest_model_Baby_Covered_in_Blanket_Sunscreen.pkl\")\n",
    "\n",
    "# --- Check and replace model ---\n",
    "if os.path.exists(model_path):\n",
    "    os.remove(model_path)\n",
    "    print(f\"Old model removed: {model_path}\")\n",
    "\n",
    "joblib.dump(clf, model_path)\n",
    "print(f\"New model saved at: {os.path.abspath(model_path)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8315e1-87a8-442f-ad23-07e9eccb4bbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7147af-43e4-4a9f-a8dc-f5a0cf13465c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc785e-2513-4d39-9958-6944664a9c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abb3c8-045c-44cc-becb-8fad83a72741",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2363cae4-8bb5-4b5e-bf6f-11979b34cba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ffce50-cc9f-4a20-bd8d-d5c92128d1d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
